{
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "QA_Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LordLean/Extracting-Green-Bonds-Use-of-Proceeds/blob/main/QA_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Retieval"
      ],
      "metadata": {
        "id": "L8R_bhw90KQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer Retriever\n"
      ],
      "metadata": {
        "id": "eM8vWuo-yz5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank-bm25\n",
        "\n",
        "!pip install PyPDF2\n",
        "\n",
        "!pip install tabula-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a90GXSgeKsMc",
        "outputId": "5b3aef2e-1bbd-4179-fb3e-b589aa844cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rank-bm25) (1.21.6)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-2.10.0-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-2.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.4.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tabula-py) (1.21.6)\n",
            "Collecting distro\n",
            "  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from tabula-py) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->tabula-py) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.3->tabula-py) (1.15.0)\n",
            "Installing collected packages: distro, tabula-py\n",
            "Successfully installed distro-1.7.0 tabula-py-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR1_ZvfpiVAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041ac9e0-c1b5-4b8a-f563-a87f35203830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-10 11:40:46--  https://www.amppartners.org/docs/default-source/investors/annual-reports/2020/2020_amp_sustainability_report.pdf\n",
            "Resolving www.amppartners.org (www.amppartners.org)... 172.67.72.70, 104.26.14.54, 104.26.15.54, ...\n",
            "Connecting to www.amppartners.org (www.amppartners.org)|172.67.72.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5034699 (4.8M) [application/pdf]\n",
            "Saving to: ‘2020_amp_sustainability_report.pdf’\n",
            "\n",
            "2020_amp_sustainabi 100%[===================>]   4.80M  1.37MB/s    in 3.4s    \n",
            "\n",
            "2022-08-10 11:40:50 (1.43 MB/s) - ‘2020_amp_sustainability_report.pdf’ saved [5034699/5034699]\n",
            "\n",
            "--2022-08-10 11:40:50--  https://www.icmagroup.org/Emails/icma-vcards/amp_combined%20hydro%20projects_External%20Review%20report.pdf\n",
            "Resolving www.icmagroup.org (www.icmagroup.org)... 91.216.93.249\n",
            "Connecting to www.icmagroup.org (www.icmagroup.org)|91.216.93.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 675346 (660K) [application/pdf]\n",
            "Saving to: ‘amp_combined hydro projects_External Review report.pdf’\n",
            "\n",
            "amp_combined hydro  100%[===================>] 659.52K  1.11MB/s    in 0.6s    \n",
            "\n",
            "2022-08-10 11:40:51 (1.11 MB/s) - ‘amp_combined hydro projects_External Review report.pdf’ saved [675346/675346]\n",
            "\n",
            "--2022-08-10 11:40:52--  https://www.globalworth.com/wp-content/uploads/2021/07/Globalworth-Green-Bond-Report-2020-20-July-2021.pdf\n",
            "Resolving www.globalworth.com (www.globalworth.com)... 195.242.93.66\n",
            "Connecting to www.globalworth.com (www.globalworth.com)|195.242.93.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1021145 (997K) [application/pdf]\n",
            "Saving to: ‘Globalworth-Green-Bond-Report-2020-20-July-2021.pdf’\n",
            "\n",
            "Globalworth-Green-B 100%[===================>] 997.21K   183KB/s    in 5.3s    \n",
            "\n",
            "2022-08-10 11:40:58 (189 KB/s) - ‘Globalworth-Green-Bond-Report-2020-20-July-2021.pdf’ saved [1021145/1021145]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.amppartners.org/docs/default-source/investors/annual-reports/2020/2020_amp_sustainability_report.pdf\n",
        "\n",
        "!wget https://www.icmagroup.org/Emails/icma-vcards/amp_combined%20hydro%20projects_External%20Review%20report.pdf\n",
        "\n",
        "!wget https://www.globalworth.com/wp-content/uploads/2021/07/Globalworth-Green-Bond-Report-2020-20-July-2021.pdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tabula\n",
        "from rank_bm25 import BM25Okapi\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "Ad0C5vgsMaec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TableReader:\n",
        "\n",
        "  def __init__(self, pdf):\n",
        "    self.pdf = pdf\n",
        "    self.dfs = None\n",
        "\n",
        "  def read_pages(self, pages=\"all\", multiple_tables=True, stream=True):\n",
        "    '''\n",
        "    Return tables discovered within pdf.\n",
        "    '''\n",
        "    self.dfs = tabula.read_pdf(self.pdf, pages=pages, multiple_tables=multiple_tables, stream=stream)\n",
        "    self.__clean_dfs()\n",
        "    return self.dfs\n",
        "\n",
        "  def __clean_dfs(self, thresh=2):\n",
        "    self.dfs = [df.dropna(thresh=thresh) for df in self.dfs]\n",
        "\n",
        "\n",
        "class Reader:\n",
        "\n",
        "  def __init__(self, filename):\n",
        "    self.reader = PdfReader(filename)\n",
        "    self.tb = TableReader(filename)\n",
        "    self.page_viewer = {page_num : {} for page_num in range(self.reader.numPages)}\n",
        "    self.idx2page_item = []\n",
        "  \n",
        "  def __extract_text(self,):\n",
        "    '''\n",
        "    Page-wise text extraction and tokenize for BM25.\n",
        "    '''\n",
        "    text_index_mem = 0\n",
        "    # List to store each tokenized corpus\n",
        "    tokenized_corpus_list = []\n",
        "    for i in range(self.reader.numPages):\n",
        "      raw_text = self.reader.getPage(i).extractText()\n",
        "      self.page_viewer[i][\"raw_text\"] = raw_text\n",
        "      # Split text\n",
        "      corpus = raw_text.split(\"\\n \\n\")\n",
        "      # Store results.\n",
        "      self.page_viewer[i][\"corpus\"] = corpus\n",
        "      for item in corpus:\n",
        "        self.idx2page_item.append((i, item)) # page,textItem\n",
        "      # Tokenize\n",
        "      tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "      tokenized_corpus_list.append(tokenized_corpus)\n",
        "    # BM25 computations only after the complete tokenized corpus is collated. \n",
        "    # Merge tokenized corpus'.\n",
        "    tokenized_corpus_complete = [item for sublist in tokenized_corpus_list for item in sublist]\n",
        "    # BM25\n",
        "    self.bm25 = BM25Okapi(tokenized_corpus_complete)\n",
        "\n",
        "  def __extract_tables(self):\n",
        "    '''\n",
        "    Page-wise table extractor.\n",
        "    '''\n",
        "    for i in range(self.reader.numPages):\n",
        "      # page=0 will throw error using tabula.\n",
        "      page = str(i+1)\n",
        "      self.page_viewer[i][\"tables\"] = self.tb.read_pages(pages=page)\n",
        "\n",
        "  def extract_pdf(self):\n",
        "    # Extract data\n",
        "    self.__extract_text()\n",
        "    self.__extract_tables()\n",
        "\n",
        "  def print_page(self, page_num):\n",
        "    '''\n",
        "    Print separated sections of text given a page.\n",
        "    '''\n",
        "    corpus = self.page_viewer[page_num][\"corpus\"]\n",
        "    for item in (corpus):\n",
        "      print(\"\\n{}\\n\".format(\"-\"*60))\n",
        "      print(item)\n",
        "    print(\"\\n{}\\n\".format(\"-\"*60))\n",
        "    for df in self.page_viewer[page_num][\"tables\"]:\n",
        "      print(df.style)\n",
        "      display(df)\n",
        "\n",
        "  def __score(self, queries, weights):\n",
        "    '''\n",
        "    Compute the average BM25 score of each given query on each page of text.\n",
        "    '''\n",
        "    self.ranked_scores = []\n",
        "    for query in queries:\n",
        "      # tokenize query by whitespace.\n",
        "      tokenized_query = query.split()\n",
        "      # Compute score.\n",
        "      doc_scores = self.bm25.get_scores(tokenized_query)\n",
        "      self.ranked_scores.append(doc_scores)\n",
        "    # Compute average (weighted) score against all queries.\n",
        "    if not len(weights):\n",
        "      # Equal weighting.\n",
        "      self.average_score = np.average(self.ranked_scores, axis=0)\n",
        "    elif len(queries) != len(weights):\n",
        "        # Unequal number of elements.\n",
        "        raise ValueError(\"Number of query and weight elements passed must be equal.\")\n",
        "    else:\n",
        "      # Weighted average.\n",
        "      self.average_score = np.average(self.ranked_scores, weights=weights, axis=0)\n",
        " \n",
        "  def get_ranked_texts(self, queries, weights=[], n=5):\n",
        "    '''\n",
        "    Return n pages which scored highest using BM25.\n",
        "    '''\n",
        "    # Run score method to calculate BM25.\n",
        "    self.__score(queries, weights)\n",
        "    idx = sorted(range(len(self.average_score)), key=lambda i: self.average_score[i], reverse=True)[:n]\n",
        "\n",
        "    final_results = []\n",
        "    for i in range(n):\n",
        "      page_num, text = self.idx2page_item[idx[i]]\n",
        "      tables = self.page_viewer[page_num][\"tables\"]\n",
        "      final_results.append({\"page_num\":page_num, \"text\":text, \"tables\":tables})\n",
        "\n",
        "    return final_results\n",
        "    "
      ],
      "metadata": {
        "id": "6vFa_DjDU15_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"Globalworth-Green-Bond-Report-2020-20-July-2021.pdf\"\n",
        "reader = Reader(filename)\n",
        "\n",
        "reader.extract_pdf()\n",
        "queries = [\n",
        "    \"use of proceeds\",\n",
        "    \"allocation of proceeds\",\n",
        "    # \"projects financed\"\n",
        "    ]\n",
        "\n",
        "top_n = 5\n",
        "top_items = reader.get_ranked_texts(queries, n=top_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2nnXaGrbwDz",
        "outputId": "17c89839-9032-46d7-f100-e759f5174cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-10 11:41:17 [WARNING] io: Got stderr: Aug 10, 2022 11:41:14 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider loadDiskCache\n",
            "WARNING: New fonts found, font cache will be re-built\n",
            "Aug 10, 2022 11:41:14 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "WARNING: Building on-disk font cache, this may take a while\n",
            "Aug 10, 2022 11:41:14 AM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "WARNING: Finished building on-disk font cache, found 17 fonts\n",
            "\n",
            "2022-08-10 11:41:44 [WARNING] io: Got stderr: Aug 10, 2022 11:41:41 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSans' for 'TimesNewRomanPSMT'\n",
            "Aug 10, 2022 11:41:44 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSans' for 'TimesNewRomanPSMT'\n",
            "\n",
            "2022-08-10 11:41:54 [WARNING] io: Got stderr: Aug 10, 2022 11:41:50 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSans' for 'TimesNewRomanPSMT'\n",
            "Aug 10, 2022 11:41:53 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSans' for 'TimesNewRomanPSMT'\n",
            "\n",
            "2022-08-10 11:42:22 [WARNING] io: Got stderr: Aug 10, 2022 11:42:21 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSans' for 'EYInterstate-Regular'\n",
            "Aug 10, 2022 11:42:22 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
            "WARNING: Using fallback font 'LiberationSans' for 'EYInterstate-Regular'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in top_items:\n",
        "  page_num = item[\"page_num\"]\n",
        "  text = item[\"text\"]\n",
        "  tables = item[\"tables\"]\n",
        "  print(\"Page: {}\\n\\n{}\".format(page_num,text))\n",
        "  for table in tables:\n",
        "    display(table.style)\n",
        "  print(\"-\"*60)\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "seidVl7E2ASC",
        "outputId": "f75a8202-2af8-4c39-c347-44561638450d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page: 4\n",
            "\n",
            "Globalworth in line with its commitment under it Green Bond Framework, to enable investors to \n",
            "follow its Green Bond progress, and to provide insight to prioritised areas, is providing this Green Bond \n",
            "update consisting of an Allocation Report and an Impact Report (where feasible) . \n",
            "The allocation of the green bond proceeds and compliance with the financ ing  or refinanc ing of  Eligible \n",
            "Green Projects  is subject to an annual external assurance by an independent third party, ERNST & \n",
            "YOUNG (HELLAS) Certified Auditors - Accountants S.A. (EY ), (as appended hereto).  \n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Page: 4\n",
            "\n",
            "Sustainal ytics Highlights on Globalworths’ Green Bond Framework (28 May 2020)  \n",
            "Use of Proceeds:  • The eligible categories for the use of proceeds, Green Buildings and \n",
            "Energy Efficiency, are aligned with those recognized by the Green Bond \n",
            "Principles 2018.  \n",
            "• Sustainalytics considers that the eligible categories wi ll lead to positive \n",
            "environmental impacts and advance the UN Sustainable Development \n",
            "Goals, specifically SDGs 7 & 11  \n",
            "Project Evaluation / \n",
            "Selection:  • Globalworth’s  internal process of evaluating and selecting projects is \n",
            "carried out by the Green Bond Committee. The Committee is responsible \n",
            "for screening projects against the eligibility criteria and recommending \n",
            "eligible projects for inclusion in the Eligible Green P roject Portfolio. The \n",
            "Portfolio will be reviewed annually to ensure projects’ eligibility and, if \n",
            "no longer eligible, projects will be removed and replaced as soon as \n",
            "practically feasible.  \n",
            "• Sustainalytics considers the project selection process in line wit h market \n",
            "practice  \n",
            "Management \n",
            "Proceeds:  • Globalworth will strive to ensure that the level of allocation to the Eligible \n",
            "Green Projects Portfolio matches or exceeds the balance of net proceeds \n",
            "from its outstanding green bonds. In case of any unallocated proc eeds, \n",
            "Globalworth will hold and/or invest, at its own discretion, in its liquidity \n",
            "portfolio.  \n",
            "• This is in line with market practice  \n",
            "Reporting:  • Globalworth intends to report on allocation of proceeds on its website, \n",
            "on an annual basis, until full allocati on. Globalworth will report on the \n",
            "total amount of allocation, the share of financing vs. refinancing and the \n",
            "details of portfolio. In addition, Globalworth is committed to reporting \n",
            "on relevant impact metrics.  \n",
            "• Sustainalytics views Globalworth’s allocatio n and impact reporting as \n",
            "aligned with market practice  \n",
            "Sustainal ytics’ independent second -party opinion published at the time of issue is available on \n",
            "Globalworth’s website:  \n",
            "www.globalworth.com/sites/default/files/2020 -07/GWI%20SPO%20%28May%202020%29.pdf  \n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Page: 6\n",
            "\n",
            "On the basis of the screening process, the Green Bond Committee will recommend eligible projects \n",
            "for inclusion as Eligible Use of Proceeds to the Board of Directors of Gl obalworth, notifying all other \n",
            "appropriate teams and committees.  \n",
            "The Green Bond Committee will review, annually or earlier if should be deemed necessary, the \n",
            "allocation of the proceeds to the Eligible Use of Proceeds and determine if any changes are necess ary \n",
            "(for instance, in the event that projects have been completed or otherwise become ineligible). While \n",
            "any Globalworth Green Bonds are outstanding, in the case of divestment or cancellation of a project \n",
            "to which proceeds have been allocated, Globalworth will reallocate the proceeds to other eligible \n",
            "projects.  \n",
            "The Green Bond Committee was held on 24 June  2021  to approve the standing properties, \n",
            "development projects and their respective allocations as at 31 December 2020  (and based on the \n",
            "indep endent valuation of the properties of the aforementioned date) and this Report . \n",
            "Selection Process  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f3a2e461d10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_5f349_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >Pre-screening based</th>\n",
              "      <th class=\"col_heading level0 col1\" >Unnamed: 0</th>\n",
              "      <th class=\"col_heading level0 col2\" >Unnamed: 1</th>\n",
              "      <th class=\"col_heading level0 col3\" >Unnamed: 2</th>\n",
              "      <th class=\"col_heading level0 col4\" >External review of</th>\n",
              "      <th class=\"col_heading level0 col5\" >Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5f349_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_5f349_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
              "      <td id=\"T_5f349_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
              "      <td id=\"T_5f349_row0_col2\" class=\"data row0 col2\" >Final validation by the</td>\n",
              "      <td id=\"T_5f349_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
              "      <td id=\"T_5f349_row0_col4\" class=\"data row0 col4\" >Eligible Use of</td>\n",
              "      <td id=\"T_5f349_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5f349_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
              "      <td id=\"T_5f349_row1_col0\" class=\"data row1 col0\" >criteria by investment</td>\n",
              "      <td id=\"T_5f349_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
              "      <td id=\"T_5f349_row1_col2\" class=\"data row1 col2\" >Green Bond</td>\n",
              "      <td id=\"T_5f349_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
              "      <td id=\"T_5f349_row1_col4\" class=\"data row1 col4\" >Proceeds with the</td>\n",
              "      <td id=\"T_5f349_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5f349_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
              "      <td id=\"T_5f349_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
              "      <td id=\"T_5f349_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
              "      <td id=\"T_5f349_row2_col2\" class=\"data row2 col2\" >Committee (annually</td>\n",
              "      <td id=\"T_5f349_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
              "      <td id=\"T_5f349_row2_col4\" class=\"data row2 col4\" >criteria displayed in</td>\n",
              "      <td id=\"T_5f349_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5f349_level0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
              "      <td id=\"T_5f349_row3_col0\" class=\"data row3 col0\" >nan</td>\n",
              "      <td id=\"T_5f349_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
              "      <td id=\"T_5f349_row3_col2\" class=\"data row3 col2\" >or earlier if necessary)</td>\n",
              "      <td id=\"T_5f349_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
              "      <td id=\"T_5f349_row3_col4\" class=\"data row3 col4\" >the Green Bond</td>\n",
              "      <td id=\"T_5f349_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5f349_level0_row4\" class=\"row_heading level0 row4\" >9</th>\n",
              "      <td id=\"T_5f349_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
              "      <td id=\"T_5f349_row4_col1\" class=\"data row4 col1\" >Eligible</td>\n",
              "      <td id=\"T_5f349_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
              "      <td id=\"T_5f349_row4_col3\" class=\"data row4 col3\" >Validated</td>\n",
              "      <td id=\"T_5f349_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
              "      <td id=\"T_5f349_row4_col5\" class=\"data row4 col5\" >Verified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5f349_level0_row5\" class=\"row_heading level0 row5\" >10</th>\n",
              "      <td id=\"T_5f349_row5_col0\" class=\"data row5 col0\" >STEP 1</td>\n",
              "      <td id=\"T_5f349_row5_col1\" class=\"data row5 col1\" >assets</td>\n",
              "      <td id=\"T_5f349_row5_col2\" class=\"data row5 col2\" >STEP 2</td>\n",
              "      <td id=\"T_5f349_row5_col3\" class=\"data row5 col3\" >nan</td>\n",
              "      <td id=\"T_5f349_row5_col4\" class=\"data row5 col4\" >STEP 3</td>\n",
              "      <td id=\"T_5f349_row5_col5\" class=\"data row5 col5\" >assets</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Page: 9\n",
            "\n",
            "6. Allocation of Proceeds  \n",
            "Globalworth’s net proceeds from its inaugural Green Bond issue in July 2020  were €386.5 million, of \n",
            "which €376.9 million or c. 97. 5% have been allocated in standing and under \n",
            "refurbishment/ construction  properties. The remainder unallocated proceeds of € 9.6  million, will be \n",
            "dedicated to financing an office  project  currently under construction  which is expected to be delivered  \n",
            "in 2021.  \n",
            "The Green Bond Committee decided to allocate the proceeds as follows:  \n",
            "Allocations:        \n",
            " Country  No of \n",
            "Buildings  Status  Certification Level  Allocated  \n",
            "Amounts \n",
            "(€m)  Unallocated  \n",
            "Amounts  \n",
            "(€m)  \n",
            "Globalworth Campus  Romania  3 Standing  BREEAM Excellent  198.4  - \n",
            "Globalworth Square  Romania  1 Under  \n",
            "Con struc tion   [BREEAM Outstanding]  40.0  9.6  \n",
            "Podium Park  A Poland  1 Standing  BREEAM Outstanding  40.3  - \n",
            "Renoma  Poland  1 Under \n",
            "Refurbishment  BREEAM Excellent  98.3  - \n",
            "TOTAL:      376.9  9.6  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f391acf0750>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_75e4a_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >Allocations:</th>\n",
              "      <th class=\"col_heading level0 col1\" >Unnamed: 0</th>\n",
              "      <th class=\"col_heading level0 col2\" >Unnamed: 1</th>\n",
              "      <th class=\"col_heading level0 col3\" >Unnamed: 2</th>\n",
              "      <th class=\"col_heading level0 col4\" >Unnamed: 3</th>\n",
              "      <th class=\"col_heading level0 col5\" >Unnamed: 4</th>\n",
              "      <th class=\"col_heading level0 col6\" >Unnamed: 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_75e4a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_75e4a_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
              "      <td id=\"T_75e4a_row0_col1\" class=\"data row0 col1\" >Country</td>\n",
              "      <td id=\"T_75e4a_row0_col2\" class=\"data row0 col2\" >No of</td>\n",
              "      <td id=\"T_75e4a_row0_col3\" class=\"data row0 col3\" >Status</td>\n",
              "      <td id=\"T_75e4a_row0_col4\" class=\"data row0 col4\" >Certification Level</td>\n",
              "      <td id=\"T_75e4a_row0_col5\" class=\"data row0 col5\" >Allocated</td>\n",
              "      <td id=\"T_75e4a_row0_col6\" class=\"data row0 col6\" >Unallocated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_75e4a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_75e4a_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
              "      <td id=\"T_75e4a_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
              "      <td id=\"T_75e4a_row1_col2\" class=\"data row1 col2\" >Buildings</td>\n",
              "      <td id=\"T_75e4a_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
              "      <td id=\"T_75e4a_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
              "      <td id=\"T_75e4a_row1_col5\" class=\"data row1 col5\" >Amounts</td>\n",
              "      <td id=\"T_75e4a_row1_col6\" class=\"data row1 col6\" >Amounts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_75e4a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_75e4a_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
              "      <td id=\"T_75e4a_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
              "      <td id=\"T_75e4a_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
              "      <td id=\"T_75e4a_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
              "      <td id=\"T_75e4a_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
              "      <td id=\"T_75e4a_row2_col5\" class=\"data row2 col5\" >(€m)</td>\n",
              "      <td id=\"T_75e4a_row2_col6\" class=\"data row2 col6\" >(€m)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_75e4a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_75e4a_row3_col0\" class=\"data row3 col0\" >Globalworth Campus</td>\n",
              "      <td id=\"T_75e4a_row3_col1\" class=\"data row3 col1\" >Romania</td>\n",
              "      <td id=\"T_75e4a_row3_col2\" class=\"data row3 col2\" >3</td>\n",
              "      <td id=\"T_75e4a_row3_col3\" class=\"data row3 col3\" >Standing</td>\n",
              "      <td id=\"T_75e4a_row3_col4\" class=\"data row3 col4\" >BREEAM Excellent</td>\n",
              "      <td id=\"T_75e4a_row3_col5\" class=\"data row3 col5\" >198.4</td>\n",
              "      <td id=\"T_75e4a_row3_col6\" class=\"data row3 col6\" >-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_75e4a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_75e4a_row4_col0\" class=\"data row4 col0\" >Globalworth Square</td>\n",
              "      <td id=\"T_75e4a_row4_col1\" class=\"data row4 col1\" >Romania</td>\n",
              "      <td id=\"T_75e4a_row4_col2\" class=\"data row4 col2\" >1</td>\n",
              "      <td id=\"T_75e4a_row4_col3\" class=\"data row4 col3\" >Under</td>\n",
              "      <td id=\"T_75e4a_row4_col4\" class=\"data row4 col4\" >[BREEAM Outstanding]</td>\n",
              "      <td id=\"T_75e4a_row4_col5\" class=\"data row4 col5\" >40.0</td>\n",
              "      <td id=\"T_75e4a_row4_col6\" class=\"data row4 col6\" >9.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_75e4a_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
              "      <td id=\"T_75e4a_row5_col0\" class=\"data row5 col0\" >Podium Park A</td>\n",
              "      <td id=\"T_75e4a_row5_col1\" class=\"data row5 col1\" >Poland</td>\n",
              "      <td id=\"T_75e4a_row5_col2\" class=\"data row5 col2\" >1</td>\n",
              "      <td id=\"T_75e4a_row5_col3\" class=\"data row5 col3\" >Standing</td>\n",
              "      <td id=\"T_75e4a_row5_col4\" class=\"data row5 col4\" >BREEAM Outstanding</td>\n",
              "      <td id=\"T_75e4a_row5_col5\" class=\"data row5 col5\" >40.3</td>\n",
              "      <td id=\"T_75e4a_row5_col6\" class=\"data row5 col6\" >-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_75e4a_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
              "      <td id=\"T_75e4a_row6_col0\" class=\"data row6 col0\" >Renoma</td>\n",
              "      <td id=\"T_75e4a_row6_col1\" class=\"data row6 col1\" >Poland</td>\n",
              "      <td id=\"T_75e4a_row6_col2\" class=\"data row6 col2\" >1</td>\n",
              "      <td id=\"T_75e4a_row6_col3\" class=\"data row6 col3\" >Under</td>\n",
              "      <td id=\"T_75e4a_row6_col4\" class=\"data row6 col4\" >BREEAM Excellent</td>\n",
              "      <td id=\"T_75e4a_row6_col5\" class=\"data row6 col5\" >98.3</td>\n",
              "      <td id=\"T_75e4a_row6_col6\" class=\"data row6 col6\" >-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_75e4a_level0_row7\" class=\"row_heading level0 row7\" >9</th>\n",
              "      <td id=\"T_75e4a_row7_col0\" class=\"data row7 col0\" >TOTAL:</td>\n",
              "      <td id=\"T_75e4a_row7_col1\" class=\"data row7 col1\" >nan</td>\n",
              "      <td id=\"T_75e4a_row7_col2\" class=\"data row7 col2\" >nan</td>\n",
              "      <td id=\"T_75e4a_row7_col3\" class=\"data row7 col3\" >nan</td>\n",
              "      <td id=\"T_75e4a_row7_col4\" class=\"data row7 col4\" >nan</td>\n",
              "      <td id=\"T_75e4a_row7_col5\" class=\"data row7 col5\" >376.9</td>\n",
              "      <td id=\"T_75e4a_row7_col6\" class=\"data row7 col6\" >9.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Page: 6\n",
            "\n",
            "• Individual measures : Individual measures reducing energy use and/or \n",
            "carbon emissions for the operational phase of the building. A list of \n",
            "eligible indivi dual measures can be found under Appendix 1 of the Green \n",
            "Bond Framework.  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f391abd2690>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_a9393_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >Pre-screening based</th>\n",
              "      <th class=\"col_heading level0 col1\" >Unnamed: 0</th>\n",
              "      <th class=\"col_heading level0 col2\" >Unnamed: 1</th>\n",
              "      <th class=\"col_heading level0 col3\" >Unnamed: 2</th>\n",
              "      <th class=\"col_heading level0 col4\" >External review of</th>\n",
              "      <th class=\"col_heading level0 col5\" >Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_a9393_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_a9393_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
              "      <td id=\"T_a9393_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
              "      <td id=\"T_a9393_row0_col2\" class=\"data row0 col2\" >Final validation by the</td>\n",
              "      <td id=\"T_a9393_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
              "      <td id=\"T_a9393_row0_col4\" class=\"data row0 col4\" >Eligible Use of</td>\n",
              "      <td id=\"T_a9393_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9393_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
              "      <td id=\"T_a9393_row1_col0\" class=\"data row1 col0\" >criteria by investment</td>\n",
              "      <td id=\"T_a9393_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
              "      <td id=\"T_a9393_row1_col2\" class=\"data row1 col2\" >Green Bond</td>\n",
              "      <td id=\"T_a9393_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
              "      <td id=\"T_a9393_row1_col4\" class=\"data row1 col4\" >Proceeds with the</td>\n",
              "      <td id=\"T_a9393_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9393_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
              "      <td id=\"T_a9393_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
              "      <td id=\"T_a9393_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
              "      <td id=\"T_a9393_row2_col2\" class=\"data row2 col2\" >Committee (annually</td>\n",
              "      <td id=\"T_a9393_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
              "      <td id=\"T_a9393_row2_col4\" class=\"data row2 col4\" >criteria displayed in</td>\n",
              "      <td id=\"T_a9393_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9393_level0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
              "      <td id=\"T_a9393_row3_col0\" class=\"data row3 col0\" >nan</td>\n",
              "      <td id=\"T_a9393_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
              "      <td id=\"T_a9393_row3_col2\" class=\"data row3 col2\" >or earlier if necessary)</td>\n",
              "      <td id=\"T_a9393_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
              "      <td id=\"T_a9393_row3_col4\" class=\"data row3 col4\" >the Green Bond</td>\n",
              "      <td id=\"T_a9393_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9393_level0_row4\" class=\"row_heading level0 row4\" >9</th>\n",
              "      <td id=\"T_a9393_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
              "      <td id=\"T_a9393_row4_col1\" class=\"data row4 col1\" >Eligible</td>\n",
              "      <td id=\"T_a9393_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
              "      <td id=\"T_a9393_row4_col3\" class=\"data row4 col3\" >Validated</td>\n",
              "      <td id=\"T_a9393_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
              "      <td id=\"T_a9393_row4_col5\" class=\"data row4 col5\" >Verified</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_a9393_level0_row5\" class=\"row_heading level0 row5\" >10</th>\n",
              "      <td id=\"T_a9393_row5_col0\" class=\"data row5 col0\" >STEP 1</td>\n",
              "      <td id=\"T_a9393_row5_col1\" class=\"data row5 col1\" >assets</td>\n",
              "      <td id=\"T_a9393_row5_col2\" class=\"data row5 col2\" >STEP 2</td>\n",
              "      <td id=\"T_a9393_row5_col3\" class=\"data row5 col3\" >nan</td>\n",
              "      <td id=\"T_a9393_row5_col4\" class=\"data row5 col4\" >STEP 3</td>\n",
              "      <td id=\"T_a9393_row5_col5\" class=\"data row5 col5\" >assets</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer Re-ranker (Neural: BERT / T5)"
      ],
      "metadata": {
        "id": "2BnnWZHubMLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygaggle\n",
        "\n",
        "!pip install transformers==4.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMzoVRC4bQA4",
        "outputId": "fa4e0d0d-4782-41ed-831b-9d7aab54291a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygaggle\n",
            "  Downloading pygaggle-0.0.3.1.tar.gz (33 kB)\n",
            "Collecting coloredlogs==14.0\n",
            "  Downloading coloredlogs-14.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 914 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from pygaggle) (1.21.6)\n",
            "Collecting pydantic==1.5\n",
            "  Downloading pydantic-1.5-cp37-cp37m-manylinux2014_x86_64.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 10.2 MB/s \n",
            "\u001b[?25hCollecting pyserini==0.10.1.0\n",
            "  Downloading pyserini-0.10.1.0-py3-none-any.whl (63.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 63.3 MB 30 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from pygaggle) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from pygaggle) (1.7.3)\n",
            "Collecting spacy==2.2.4\n",
            "  Downloading spacy-2.2.4-cp37-cp37m-manylinux1_x86_64.whl (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pygaggle) (2.8.0)\n",
            "Requirement already satisfied: tensorflow>=2.2.0rc1 in /usr/local/lib/python3.7/dist-packages (from pygaggle) (2.8.2+zzzcolab20220719082949)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 35.5 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.45.0\n",
            "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting transformers==4.0.0\n",
            "  Downloading transformers-4.0.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 34.0 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.94\n",
            "  Downloading sentencepiece-0.1.94-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 26.2 MB/s \n",
            "\u001b[?25hCollecting humanfriendly>=7.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from pyserini==0.10.1.0->pygaggle) (0.29.32)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 17.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyserini==0.10.1.0->pygaggle) (1.3.5)\n",
            "Collecting pyjnius\n",
            "  Downloading pyjnius-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 36.4 MB/s \n",
            "\u001b[?25hCollecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->pygaggle) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->pygaggle) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->pygaggle) (57.4.0)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->pygaggle) (2.0.6)\n",
            "Collecting thinc==7.4.0\n",
            "  Downloading thinc-7.4.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->pygaggle) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->pygaggle) (3.0.6)\n",
            "Collecting blis<0.5.0,>=0.4.0\n",
            "  Downloading blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 40.8 MB/s \n",
            "\u001b[?25hCollecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.0->pygaggle) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.0->pygaggle) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.0.0->pygaggle) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4->pygaggle) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4->pygaggle) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4->pygaggle) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->pygaggle) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->pygaggle) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->pygaggle) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->pygaggle) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->pygaggle) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->pygaggle) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (1.2.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (1.47.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.1.0->pygaggle) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.1.0->pygaggle) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.1.0->pygaggle) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.1.0->pygaggle) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.1.0->pygaggle) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.1.0->pygaggle) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.1.0->pygaggle) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.1.0->pygaggle) (3.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (0.26.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0rc1->pygaggle) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2.0rc1->pygaggle) (1.5.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.0.0->pygaggle) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyserini==0.10.1.0->pygaggle) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyserini==0.10.1.0->pygaggle) (2022.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.0.0->pygaggle) (7.1.2)\n",
            "Building wheels for collected packages: pygaggle, sacremoses\n",
            "  Building wheel for pygaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygaggle: filename=pygaggle-0.0.3.1-py3-none-any.whl size=51498 sha256=94b9d2873d1c5961577911d9feb564882ddfc2c46c0590dfeaf11e2ea926a023\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/b7/35/6b19949b191b7b5005739e020b91b3a625c3a588a0bd49d70c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=1a046c904a9a6a12f8866f69c14bb73852ebc26e38c84c21b3967b9496bf68de\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built pygaggle sacremoses\n",
            "Installing collected packages: tqdm, srsly, plac, catalogue, blis, tokenizers, thinc, sacremoses, pyjnius, humanfriendly, faiss-cpu, transformers, spacy, sentencepiece, pyserini, pydantic, coloredlogs, pygaggle\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.4\n",
            "    Uninstalling srsly-2.4.4:\n",
            "      Successfully uninstalled srsly-2.4.4\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.8\n",
            "    Uninstalling blis-0.7.8:\n",
            "      Successfully uninstalled blis-0.7.8\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.0\n",
            "    Uninstalling thinc-8.1.0:\n",
            "      Successfully uninstalled thinc-8.1.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.9.1\n",
            "    Uninstalling pydantic-1.9.1:\n",
            "      Successfully uninstalled pydantic-1.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.45.0 which is incompatible.\n",
            "en-core-web-sm 3.4.0 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.2.4 which is incompatible.\u001b[0m\n",
            "Successfully installed blis-0.4.1 catalogue-1.0.0 coloredlogs-14.0 faiss-cpu-1.7.2 humanfriendly-10.0 plac-1.1.3 pydantic-1.5 pygaggle-0.0.3.1 pyjnius-1.4.2 pyserini-0.10.1.0 sacremoses-0.0.53 sentencepiece-0.1.94 spacy-2.2.4 srsly-1.0.5 thinc-7.4.0 tokenizers-0.9.4 tqdm-4.45.0 transformers-4.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.6.1\n",
            "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1) (0.0.53)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1) (4.12.0)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1) (2022.6.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1) (4.45.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.6.1) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.6.1) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.1) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1) (2022.6.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.1) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.1) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.1) (1.15.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.9.4\n",
            "    Uninstalling tokenizers-0.9.4:\n",
            "      Successfully uninstalled tokenizers-0.9.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.0.0\n",
            "    Uninstalling transformers-4.0.0:\n",
            "      Successfully uninstalled transformers-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pygaggle 0.0.3.1 requires tokenizers==0.9.4, but you have tokenizers 0.10.3 which is incompatible.\n",
            "pygaggle 0.0.3.1 requires transformers==4.0.0, but you have transformers 4.6.1 which is incompatible.\u001b[0m\n",
            "Successfully installed huggingface-hub-0.0.8 tokenizers-0.10.3 transformers-4.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pygaggle.rerank.base import Query, Text\n",
        "from pygaggle.rerank.transformer import MonoT5, MonoBERT\n",
        "\n",
        "class Reranker:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.mono5t = MonoT5()\n",
        "    self.monobert = MonoBERT()\n",
        "\n",
        "  def rerank(self, query, texts, method=\"T5\"):\n",
        "    query = Query(query)\n",
        "    texts = [Text(text, {\"docid\" : i}, 0) for i, text in enumerate(texts)]\n",
        "\n",
        "    if method == \"T5\":\n",
        "      reranker = self.mono5t\n",
        "    if method == \"BERT\":\n",
        "      reranker = self.monobert\n",
        "\n",
        "    reranked = reranker.rerank(query, texts)\n",
        "    reranked.sort(key=lambda x: x.score, reverse=True)\n",
        "\n",
        "    return reranked"
      ],
      "metadata": {
        "id": "HM4Qf8PmbTy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reranker = Reranker()\n",
        "\n",
        "query = \"what did the use of proceeds finance\"\n",
        "\n",
        "texts = [item[\"text\"] for item in top_items]\n",
        "\n",
        "reranked = reranker.rerank(query, texts, method=\"T5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJwTmWmxjqBi",
        "outputId": "b96031c9-6e37-4635-913c-e579801ca76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:173: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out reranked results:\n",
        "for i in range(len(reranked)):\n",
        "  print(i)\n",
        "  print(\"Score: {}\".format(reranked[i].score))\n",
        "  print(\"Text:\\n{}\".format(reranked[i].text))\n",
        "  print(\"\\n\\n{}\".format(\"-\"*60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oim7DOxCk5oa",
        "outputId": "18dc2bc7-2b4b-476b-9ae3-8938a303eae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Score: -0.011511215940117836\n",
            "Text:\n",
            "Sustainal ytics Highlights on Globalworths’ Green Bond Framework (28 May 2020)  \n",
            "Use of Proceeds:  • The eligible categories for the use of proceeds, Green Buildings and \n",
            "Energy Efficiency, are aligned with those recognized by the Green Bond \n",
            "Principles 2018.  \n",
            "• Sustainalytics considers that the eligible categories wi ll lead to positive \n",
            "environmental impacts and advance the UN Sustainable Development \n",
            "Goals, specifically SDGs 7 & 11  \n",
            "Project Evaluation / \n",
            "Selection:  • Globalworth’s  internal process of evaluating and selecting projects is \n",
            "carried out by the Green Bond Committee. The Committee is responsible \n",
            "for screening projects against the eligibility criteria and recommending \n",
            "eligible projects for inclusion in the Eligible Green P roject Portfolio. The \n",
            "Portfolio will be reviewed annually to ensure projects’ eligibility and, if \n",
            "no longer eligible, projects will be removed and replaced as soon as \n",
            "practically feasible.  \n",
            "• Sustainalytics considers the project selection process in line wit h market \n",
            "practice  \n",
            "Management \n",
            "Proceeds:  • Globalworth will strive to ensure that the level of allocation to the Eligible \n",
            "Green Projects Portfolio matches or exceeds the balance of net proceeds \n",
            "from its outstanding green bonds. In case of any unallocated proc eeds, \n",
            "Globalworth will hold and/or invest, at its own discretion, in its liquidity \n",
            "portfolio.  \n",
            "• This is in line with market practice  \n",
            "Reporting:  • Globalworth intends to report on allocation of proceeds on its website, \n",
            "on an annual basis, until full allocati on. Globalworth will report on the \n",
            "total amount of allocation, the share of financing vs. refinancing and the \n",
            "details of portfolio. In addition, Globalworth is committed to reporting \n",
            "on relevant impact metrics.  \n",
            "• Sustainalytics views Globalworth’s allocatio n and impact reporting as \n",
            "aligned with market practice  \n",
            "Sustainal ytics’ independent second -party opinion published at the time of issue is available on \n",
            "Globalworth’s website:  \n",
            "www.globalworth.com/sites/default/files/2020 -07/GWI%20SPO%20%28May%202020%29.pdf  \n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "1\n",
            "Score: -0.4424667954444885\n",
            "Text:\n",
            "On the basis of the screening process, the Green Bond Committee will recommend eligible projects \n",
            "for inclusion as Eligible Use of Proceeds to the Board of Directors of Gl obalworth, notifying all other \n",
            "appropriate teams and committees.  \n",
            "The Green Bond Committee will review, annually or earlier if should be deemed necessary, the \n",
            "allocation of the proceeds to the Eligible Use of Proceeds and determine if any changes are necess ary \n",
            "(for instance, in the event that projects have been completed or otherwise become ineligible). While \n",
            "any Globalworth Green Bonds are outstanding, in the case of divestment or cancellation of a project \n",
            "to which proceeds have been allocated, Globalworth will reallocate the proceeds to other eligible \n",
            "projects.  \n",
            "The Green Bond Committee was held on 24 June  2021  to approve the standing properties, \n",
            "development projects and their respective allocations as at 31 December 2020  (and based on the \n",
            "indep endent valuation of the properties of the aforementioned date) and this Report . \n",
            "Selection Process  \n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "2\n",
            "Score: -4.839536666870117\n",
            "Text:\n",
            "6. Allocation of Proceeds  \n",
            "Globalworth’s net proceeds from its inaugural Green Bond issue in July 2020  were €386.5 million, of \n",
            "which €376.9 million or c. 97. 5% have been allocated in standing and under \n",
            "refurbishment/ construction  properties. The remainder unallocated proceeds of € 9.6  million, will be \n",
            "dedicated to financing an office  project  currently under construction  which is expected to be delivered  \n",
            "in 2021.  \n",
            "The Green Bond Committee decided to allocate the proceeds as follows:  \n",
            "Allocations:        \n",
            " Country  No of \n",
            "Buildings  Status  Certification Level  Allocated  \n",
            "Amounts \n",
            "(€m)  Unallocated  \n",
            "Amounts  \n",
            "(€m)  \n",
            "Globalworth Campus  Romania  3 Standing  BREEAM Excellent  198.4  - \n",
            "Globalworth Square  Romania  1 Under  \n",
            "Con struc tion   [BREEAM Outstanding]  40.0  9.6  \n",
            "Podium Park  A Poland  1 Standing  BREEAM Outstanding  40.3  - \n",
            "Renoma  Poland  1 Under \n",
            "Refurbishment  BREEAM Excellent  98.3  - \n",
            "TOTAL:      376.9  9.6  \n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "3\n",
            "Score: -13.390205383300781\n",
            "Text:\n",
            "Globalworth in line with its commitment under it Green Bond Framework, to enable investors to \n",
            "follow its Green Bond progress, and to provide insight to prioritised areas, is providing this Green Bond \n",
            "update consisting of an Allocation Report and an Impact Report (where feasible) . \n",
            "The allocation of the green bond proceeds and compliance with the financ ing  or refinanc ing of  Eligible \n",
            "Green Projects  is subject to an annual external assurance by an independent third party, ERNST & \n",
            "YOUNG (HELLAS) Certified Auditors - Accountants S.A. (EY ), (as appended hereto).  \n",
            "\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "4\n",
            "Score: -14.383399963378906\n",
            "Text:\n",
            "• Individual measures : Individual measures reducing energy use and/or \n",
            "carbon emissions for the operational phase of the building. A list of \n",
            "eligible indivi dual measures can be found under Appendix 1 of the Green \n",
            "Bond Framework.  \n",
            "\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QA Model"
      ],
      "metadata": {
        "id": "stSjl2v60UOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download zipped model\n",
        "!gdown 1NBc9MfT4FuchadevFJvcfyBfpIPMILb0\n",
        "\n",
        "# Unzip\n",
        "!unzip finbert-pretrain-finetuned-squad.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjCOuqJr0V7c",
        "outputId": "a8d8a553-1bb7-46ef-c084-e8c11c06a771"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NBc9MfT4FuchadevFJvcfyBfpIPMILb0\n",
            "To: /content/finbert-pretrain-finetuned-squad.zip\n",
            "100% 406M/406M [00:06<00:00, 61.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers \n",
        "\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaRQa9-U0qwe",
        "outputId": "f286e9ca-c00a-4000-a0ca-4d09e0bff24a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"finbert-pretrain-finetuned-squad\"\n",
        "\n",
        "question_answering = pipeline(\"question-answering\", model=model_dir, tokenizer=model_dir)"
      ],
      "metadata": {
        "id": "NcRV_F-H08df"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\n",
        "Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\n",
        "\"\"\"\n",
        "question = \"what are the machine learning models based on?\"\n",
        "\n",
        "question, context = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\""
      ],
      "metadata": {
        "id": "ocIsSumr1Haf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = question_answering(question=question, context=context, device=0)\n",
        "print(\"Answer:\", result['answer'])\n",
        "print(\"Score:\", result['score'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4ljNTRZ1Kmo",
        "outputId": "cbadb88c-9847-4d1e-8f21-80a5a2897775"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: a nice puppet\n",
            "Score: 0.49829721450805664\n"
          ]
        }
      ]
    }
  ]
}